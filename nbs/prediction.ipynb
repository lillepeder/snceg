{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae76ee6",
   "metadata": {},
   "source": [
    "# Running predictions with snceg\n",
    "In this notebook we will download and apply our pretrained Attention U-Net to an example neuromelanin MRI.\n",
    "\n",
    "[Model repository](https://huggingface.co/lillepeder/SNceg-0.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead6d0a-37e0-49d4-a063-519bf9586493",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746726e-002f-4c94-9f55-1c6de3e5f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# add snceg.py to the system path\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7af22-7e0f-461d-be74-4fd609cb3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "from snceg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c3543a-75c2-41d4-81e9-c656efe44aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = (288,384, 48)\n",
    "target_res = (.677, .677, 1.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eabccbb-afcf-40bf-894e-cf160d63d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample\n",
    "resampled_nimg = conform(nimg, target_shape, target_res)\n",
    "\n",
    "# Save output\n",
    "out_name = f\"{fn.parent / fn.stem}_RESAMPLED.nii.gz\"\n",
    "resampled_nimg.to_filename(out_name)\n",
    "\n",
    "print(out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06871cb4-f9cd-4733-b0e3-19c77d15e6dd",
   "metadata": {},
   "source": [
    "# Download the model from HuggingFace\n",
    "The model and its parameters are saved to `../models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba2fbb-ca96-4a6f-8a11-1b2b850686ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_download(repo_id=\"lillepeder/SNceg-0.1\", local_dir='../models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e0d14-7953-4f04-a55f-7479ddac39aa",
   "metadata": {},
   "source": [
    "## A quick note on resampling\n",
    "\n",
    "The model was trained primarily on anisotropic images of resolution $(0.677 \\times 0.677 \\times 1.340) mmÂ³$, so we resample the image prior to prediction and resample back to the original image.\n",
    "\n",
    "This and more is fetched with `load_variables`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2145a-7bd4-4738-9eb3-e3b057d2ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size, reorder, resample = load_variables(pkl_fn='../models/vars_SNceg-0.1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6eaf5-feb7-4d0f-a832-150d18df70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(size, reorder, resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd694ac-0681-44b4-8988-c055191f3ad3",
   "metadata": {},
   "source": [
    "In the rare case that your data is already close to the given resolution, you can override the resampling by uncommenting the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0c1f7-c9ee-4b99-937e-6120d6c2a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f4e36-ea68-4d43-9beb-568c9fc925ad",
   "metadata": {},
   "source": [
    "# Load the model into memory\n",
    "This step is made extremely easy by fastAI's `load_learner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe0f30-7858-4e52-9e65-3a6f784df054",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = '../models/SNceg-0.1.pkl'\n",
    "learner = load_learner(model_fn)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ccc3eff-354a-4936-bfb8-043a65488839",
   "metadata": {},
   "source": [
    "base_dir = Path('../data/').absolute().resolve()\n",
    "\n",
    "# SELECT INPUT FILE\n",
    "fn = base_dir / 'mean_NM.nii.gz'\n",
    "print(fn)\n",
    "\n",
    "nimg = nib.load(fn)\n",
    "print(nimg.shape, '\\n', nimg.header.get_zooms())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af5c9b-ce46-4eb6-a961-59e695a13089",
   "metadata": {},
   "source": [
    "# Predict\n",
    "And just like that we can apply it to our input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbefdf-9d8a-4205-8b19-b56b16982e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input image\n",
    "input_fn = '../data/mean_NM.nii.gz'\n",
    "\n",
    "# path of the output\n",
    "output_fn = '../data/SN_prediction.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef241c-d3cb-4d50-b6e9-fefd7584b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = run_one_sample(fn=input_fn, \n",
    "               learner=learner, \n",
    "               reorder=reorder, \n",
    "               resample=resample,\n",
    "               pred_fn=output_fn\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28c478-82c8-439f-b614-3368476028e5",
   "metadata": {},
   "source": [
    "# Visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c75c7-700b-4bfd-8c51-dc921ad29403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchio import Subject, ScalarImage, LabelMap\n",
    "\n",
    "subject = Subject(image=ScalarImage(input_fn), mask=LabelMap(output_fn))\n",
    "\n",
    "subject.plot(figsize=(20,8),\n",
    "             percentiles=(0.5, 99.9),\n",
    "             indices=(95,110,118),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf79b2a-b24d-4406-a172-90644cc6a377",
   "metadata": {},
   "source": [
    "## Or you can view it in your viewer of choice, e.g. Freeview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2be14-af4e-421f-9136-5fdf2e0713a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!freeview {input_fn} {output_fn}:colormap=lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cf9c2-612c-4726-b159-ca2a5a59d614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snceg",
   "language": "python",
   "name": "snceg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
